# AI Otoscope  

Репозиторий для проекта **ИИ-Отоскоп**.  
Система компьютерного зрения для анализа изображений, полученных при отоскопии.  
Цель — помощь врачу в выявлении патологий уха с использованием методов искусственного интеллекта. 

## Математическая модель

В проекте используется ансамблевая модель, объединяющая несколько архитектур из библиотеки **timm**.  

Для каждого входного изображения `x`:  
- каждая модель `m` вычисляет вектор логитов `z^(m)` размерности `C` (число классов);  
- логиты преобразуются в вероятности через сигмоиду: `p^(m) = sigmoid(z^(m))`;  
- формируется набор прогнозов: `p^(1), p^(2), ..., p^(M)`;  

Далее агрегируются результаты:  
- **средняя вероятность**: усреднение по всем моделям;  
- **стандартное отклонение**: мера разброса вероятностей между моделями (оценка неопределённости);  
- **средние логиты**: используются как итоговое представление для обучения.  

Таким образом, модель возвращает:  
- индивидуальные прогнозы каждой архитектуры,  
- усреднённые вероятности (основное предсказание ансамбля),  
- стандартное отклонение вероятностей (для оценки уверенности),  
- усреднённые логиты (для функции потерь).  

Ансамбль повышает устойчивость к ошибкам отдельных моделей и позволяет лучше оценивать надёжность предсказаний.

## Формат входных данных

Модель работает с изображениями.  

- **Тип данных**: RGB-изображения.  
- **Размер**: `224 × 224` пикселей (каждое изображение приводится к этому размеру при предобработке).  
- **Формат тензора**: `FloatTensor` размерности `[B, 3, 224, 224]`,  
  где  
  - `B` — размер batch (число изображений в пакете),  
  - `3` — количество каналов (RGB),  
  - `224 × 224` — пространственные размеры.  
- **Нормализация**: значения пикселей приводятся к диапазону `[0, 1]` и стандартизируются  
  (по умолчанию используются mean/std из ImageNet).

## Пример использования

```python
import torch
from PIL import Image
from torchvision import transforms
from model import EnsembleModel  # импорт твоей модели

# 1. Загружаем изображение
image = Image.open("example.jpg").convert("RGB")

# 2. Преобразования (resize + тензор + нормализация)
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.485, 0.456, 0.406],  # стандартные ImageNet mean
        std=[0.229, 0.224, 0.225]    # стандартные ImageNet std
    )
])
x = transform(image).unsqueeze(0)   # размер [1, 3, 224, 224]

# 3. Прогон через модель
model = EnsembleModel(num_classes=5)
logits_stack, probs_stack, avg_probs, std_probs, avg_logits = model(x)

print("Форма входа:", x.shape)           # torch.Size([1, 3, 224, 224])
print("Форма выходных вероятностей:", avg_probs.shape)  # torch.Size([1, 5])
```
## Процесс обучения и инференса

### Постановка задачи
Модель решает задачу **многометочной (multi-label) классификации** изображений уха. На выходе — по одному логиту/вероятности на каждый из `C` классов (в коде `num_classes=5`). Ансамбль объединяет несколько моделей из `timm` и агрегирует их предсказания.

### Архитектура и агрегация
Используется ансамблевая обёртка `EnsembleModel` с `M` базовыми моделями (в коде активен `beit3_large_patch16_224`, остальные подготовлены к подключению). Для входного батча `x` каждая модель выдаёт логиты `z^(m)`. Далее:
- рассчитываются вероятности `p^(m) = sigmoid(z^(m))`;
- по ансамблю считаются **средние вероятности** `avg_probs` (основной предиктор на инференсе),
- **стандартное отклонение** `std_probs` (оценка разброса/неопределённости),
- **средние логиты** `avg_logits` (удобны для функции потерь).

Возвращаются: стеки логитов/вероятностей по моделям, а также `avg_probs`, `std_probs`, `avg_logits`.

### Данные и сплит
Из Excel-таблицы отбираются записи с валидным качеством (`"Финал Качество" != "нет"`), после чего выполняется случайное разбиение на `train/val` (по умолчанию 80/20, `random_state=1`).  
Вход — RGB-изображения, приводимые к `224×224`.

### Предобработка и аугментации
- **Train**: Resize(224,224), HorizontalFlip, Rotation(±15°), ColorJitter (яркость/контраст/насыщенность), GaussianBlur (по вероятности), ToTensor, RandomErasing (после ToTensor), Normalize (ImageNet mean/std).
- **Val**: Resize(224,224), ToTensor, Normalize (ImageNet mean/std).

### Функция потерь и дисбаланс классов
Так как задача многометочная, используется **`BCEWithLogitsLoss`**. Для компенсации дисбаланса считается `pos_weight` на основе частоты положительных/отрицательных примеров по каждому классу и передаётся в лосс.  
В коде также предусмотрены альтернативы:
- взвешенная BCE по классам (`WeightedBCEWithLogitsLoss`),
- гибрид BCE + Focal (`MixedLoss` с `BinaryFocalLoss`) — удобно при сильном дисбалансе.

### Оптимизация и гиперпараметры (по умолчанию в коде)
- Оптимизатор: **AdamW**, `lr=5e-6`, `weight_decay=1e-4`.
- Батч-размер: `2` для обучения, `1` для валидации.
- Эпохи: `50` (early stopping не включён; сохранение — по лучшему скору).
- Устройство: `cuda:2` при наличии GPU.

### Критерий отбора лучшей модели
На валидации для каждого класса считаются **Precision, Recall (Sensitivity), Specificity, F1** при пороге `0.5` на вероятностях `sigmoid(avg_logits)`.  
Ключевой скор — **средний F1** по целевым классам `['отит гнойный', 'отит негнойный']`. Если текущий средний F1 улучшается, веса сохраняются в `weights6/best_ensemble_model{epoch}.pth`.

> Примечание: порог `0.5` выбран константно для всех классов. Для практического применения имеет смысл **калибровать пороги по классам** (например, по максимуму F1/Youden J на валидации), особенно при несимметричных издержках ошибок.

### Инференс
На инференсе используется агрегированный прогноз ансамбля:
1) прогон изображения через все базовые модели;
2) усреднение (по моделям) — либо логитов с последующим `sigmoid(avg_logits)`, либо вероятностей `avg_probs`;
3) получение многометочной разметки по порогам (в коде — 0.5).  
Дополнительно можно использовать `std_probs` как индикатор **неопределённости**: высокий разброс предсказаний между моделями сигнализирует о необходимости пересмотра/второго мнения.

### Метрики отчёта
Для каждого класса выводятся:
- **Precision**, **Recall (Sensitivity)**, **Specificity**, **F1**,
а также логируется улучшение лучшей модели по целевому среднему F1.

### Ключевые решения дизайна (почему так)
- **Ансамбль** сглаживает ошибки отдельных архитектур и выдаёт устойчивый прогноз; `std_probs` даёт бесплатную оценку надёжности.
- **BCEWithLogits + pos_weight** — естественный выбор для multi-label; альтернативы (Focal/Mixed) полезны при сильном дисбалансе или доминировании лёгких примеров.
- **Жёсткий общий порог 0.5** — базовый старт, но **класс-специфичная калибровка порогов** обычно добавляет ощутимый прирост клинической полезности.
