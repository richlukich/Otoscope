# AI Otoscope  

Репозиторий для проекта **ИИ-Отоскоп**.  
Система компьютерного зрения для анализа изображений, полученных при отоскопии.  
Цель — помощь врачу в выявлении патологий уха с использованием методов искусственного интеллекта. 

## Установка

```bash
# 1) создать и активировать окружение (Python 3.12 ок)
python3.12 -m venv otoscope
source otoscope/bin/activate

# 2) обновить pip
pip install --upgrade pip

# 3) Linux + Nvidia GPU (Cuda 12.1)
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121

# 4) Остальные зависимости проекта
pip install -r requirements.txt
```


## Математическая модель

В проекте используется ансамблевая модель, объединяющая несколько архитектур из библиотеки **timm**.  

Для каждого входного изображения `x`:  
- каждая модель `m` вычисляет вектор логитов `z^(m)` размерности `C` (число классов);  
- логиты преобразуются в вероятности через сигмоиду: `p^(m) = sigmoid(z^(m))`;  
- формируется набор прогнозов: `p^(1), p^(2), ..., p^(M)`;  

Далее агрегируются результаты:  
- **средняя вероятность**: усреднение по всем моделям;  
- **стандартное отклонение**: мера разброса вероятностей между моделями (оценка неопределённости);  
- **средние логиты**: используются как итоговое представление для обучения.  

Таким образом, модель возвращает:  
- индивидуальные прогнозы каждой архитектуры,  
- усреднённые вероятности (основное предсказание ансамбля),  
- стандартное отклонение вероятностей (для оценки уверенности),  
- усреднённые логиты (для функции потерь).  

Ансамбль повышает устойчивость к ошибкам отдельных моделей и позволяет лучше оценивать надёжность предсказаний.

## Формат входных данных

Модель работает с изображениями.  

- **Тип данных**: RGB-изображения.  
- **Размер**: `224 × 224` пикселей (каждое изображение приводится к этому размеру при предобработке).  
- **Формат тензора**: `FloatTensor` размерности `[B, 3, 224, 224]`,  
  где  
  - `B` — размер batch (число изображений в пакете),  
  - `3` — количество каналов (RGB),  
  - `224 × 224` — пространственные размеры.  
- **Нормализация**: значения пикселей приводятся к диапазону `[0, 1]` и стандартизируются  
  (по умолчанию используются mean/std из ImageNet).

## Пример использования

```python
import torch
from PIL import Image
from torchvision import transforms
from model import EnsembleModel  # импорт твоей модели

# 1. Загружаем изображение
image = Image.open("example.jpg").convert("RGB")

# 2. Преобразования (resize + тензор + нормализация)
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.485, 0.456, 0.406],  # стандартные ImageNet mean
        std=[0.229, 0.224, 0.225]    # стандартные ImageNet std
    )
])
x = transform(image).unsqueeze(0)   # размер [1, 3, 224, 224]

# 3. Прогон через модель
model = EnsembleModel(num_classes=5)
logits_stack, probs_stack, avg_probs, std_probs, avg_logits = model(x)

print("Форма входа:", x.shape)           # torch.Size([1, 3, 224, 224])
print("Форма выходных вероятностей:", avg_probs.shape)  # torch.Size([1, 5])
```
## Процесс обучения и инференса

### Постановка задачи
Модель решает задачу **многометочной (multi-label) классификации** изображений уха. На выходе — по одному логиту/вероятности на каждый из `C` классов (в коде `num_classes=5`). Ансамбль объединяет несколько моделей из `timm` и агрегирует их предсказания.

### Архитектура и агрегация
Используется ансамблевая обёртка `EnsembleModel` с `M` базовыми моделями (в коде активен `beit3_large_patch16_224`, остальные подготовлены к подключению). Для входного батча `x` каждая модель выдаёт логиты `z^(m)`. Далее:
- рассчитываются вероятности `p^(m) = sigmoid(z^(m))`;
- по ансамблю считаются **средние вероятности** `avg_probs` (основной предиктор на инференсе),
- **стандартное отклонение** `std_probs` (оценка разброса/неопределённости),
- **средние логиты** `avg_logits` (удобны для функции потерь).

Возвращаются: стеки логитов/вероятностей по моделям, а также `avg_probs`, `std_probs`, `avg_logits`.

### Данные и сплит
Из Excel-таблицы отбираются записи с валидным качеством (`"Финал Качество" != "нет"`), после чего выполняется случайное разбиение на `train/val` (по умолчанию 80/20, `random_state=1`).  
Вход — RGB-изображения, приводимые к `224×224`.

### Предобработка и аугментации
- **Train**: Resize(224,224), HorizontalFlip, Rotation(±15°), ColorJitter (яркость/контраст/насыщенность), GaussianBlur (по вероятности), ToTensor, RandomErasing (после ToTensor), Normalize (ImageNet mean/std).
- **Val**: Resize(224,224), ToTensor, Normalize (ImageNet mean/std).

### Функция потерь и дисбаланс классов
Так как задача многометочная, используется **`BCEWithLogitsLoss`**. Для компенсации дисбаланса считается `pos_weight` на основе частоты положительных/отрицательных примеров по каждому классу и передаётся в лосс.  
В коде также предусмотрены альтернативы:
- взвешенная BCE по классам (`WeightedBCEWithLogitsLoss`),
- гибрид BCE + Focal (`MixedLoss` с `BinaryFocalLoss`) — удобно при сильном дисбалансе.

### Оптимизация и гиперпараметры (по умолчанию в коде)
- Оптимизатор: **AdamW**, `lr=5e-6`, `weight_decay=1e-4`.
- Батч-размер: `2` для обучения, `1` для валидации.
- Эпохи: `50` (early stopping не включён; сохранение — по лучшему скору).
- Устройство: `cuda:2` при наличии GPU.

### Критерий отбора лучшей модели
На валидации для каждого класса считаются **Precision, Recall (Sensitivity), Specificity, F1** при пороге `0.5` на вероятностях `sigmoid(avg_logits)`.  
Ключевой скор — **средний F1** по целевым классам `['отит гнойный', 'отит негнойный']`. Если текущий средний F1 улучшается, веса сохраняются в `weights6/best_ensemble_model{epoch}.pth`.

> Примечание: порог `0.5` выбран константно для всех классов. Для практического применения имеет смысл **калибровать пороги по классам** (например, по максимуму F1/Youden J на валидации), особенно при несимметричных издержках ошибок.

### Инференс
На инференсе используется агрегированный прогноз ансамбля:
1) прогон изображения через все базовые модели;
2) усреднение (по моделям) — либо логитов с последующим `sigmoid(avg_logits)`, либо вероятностей `avg_probs`;
3) получение многометочной разметки по порогам (в коде — 0.5).  
Дополнительно можно использовать `std_probs` как индикатор **неопределённости**: высокий разброс предсказаний между моделями сигнализирует о необходимости пересмотра/второго мнения.

### Метрики отчёта
Для каждого класса выводятся:
- **Precision**, **Recall (Sensitivity)**, **Specificity**, **F1**,
а также логируется улучшение лучшей модели по целевому среднему F1.

### Ключевые решения дизайна (почему так)
- **Ансамбль** сглаживает ошибки отдельных архитектур и выдаёт устойчивый прогноз; `std_probs` даёт бесплатную оценку надёжности.
- **BCEWithLogits + pos_weight** — естественный выбор для multi-label; альтернативы (Focal/Mixed) полезны при сильном дисбалансе или доминировании лёгких примеров.
- **Жёсткий общий порог 0.5** — базовый старт, но **класс-специфичная калибровка порогов** обычно добавляет ощутимый прирост клинической полезности.

## Инференс

Инференс выполняется с помощью скрипта `inference/inference_test.py`.  
Он прогоняет модель по директории с изображениями, сравнивает с GT-таблицей и сохраняет предсказания и метрики.

### Формат входных данных
- **Изображения**: RGB, имена файлов совпадают с `study_id` в GT-таблице.  
- **GT-таблица**: CSV или Excel с колонками: study_id, NORM, OP, ONP, CI, OTH
где значения `0/1` указывают на отсутствие или наличие класса:
- `NORM` — норма  
- `OP` — острый гнойный отит  
- `ONP` — острый негнойный отит  
- `CI` — серная пробка  
- `OTH` — другие патологии
### Запуск
```bash
python inference_test.py \
--images_dir /path/to/Уши \
--gt_csv /path/to/gt_converted_test.csv \
--weights /path/to/best_ensemble_model33.pth \
--out_preds_csv "outputs/preds.csv" \
--metrics_csv "outputs/metrics.csv" \
--auto_tune_otitis \
--r_min 0.80 \
--p_min 0.80 \
--norm_veto_th 0.90 \
--sulfur_veto_th 0.85 \
--ng_margin 0.10 \
--device cuda:0 \
--batch_size 1
```
### Что делает скрипт
1. Загружает изображения и GT-таблицу.  
2. Прогоняет изображения через ансамблевую модель (**EnsembleModel**).  
3. Считает вероятности (`sigmoid(avg_logits)`), бинаризует по порогам.  
4. Применяет пост-обработку:  
   - **veto нормой** (`--norm_veto_th`) — если уверенность в норме выше порога, то гнойный отит выключается.  
   - **veto серной пробкой** (`--sulfur_veto_th`) — аналогично для CI.  
   - **приоритет негнойного** (`--ng_margin`) — если активны оба отита, но негнойный заметно сильнее, то гнойный выключается.  
5. Сохраняет предсказания и метрики.  

### Формат предсказаний
CSV (`out_preds_csv`) имеет вид:
study_id,norm,op,onp,ci,oth

IMG_001.jpg,1,0,0,0,0

IMG_002.jpg,0,1,0,0,0

IMG_003.jpg,0,0,1,0,0

IMG_004.jpg,0,0,0,1,0

### Формат метрик
CSV (`metrics_csv`) содержит:
class,threshold,precision,recall,specificity,f1,accuracy

NORM,0.500,0.900,0.970,0.876,0.934,0.927

OP,0.019,0.868,0.805,0.985,0.835,0.966

ONP,0.208,0.814,0.838,0.958,0.826,0.937

CI,0.500,0.879,0.967,0.989,0.921,0.987

OTH,0.500,0.509,0.643,0.923,0.568,0.892


### Полезные флаги
- `--auto_tune_otitis` — тюнинг порогов OP/ONP под Recall ≥ `r_min` и Precision ≥ `p_min`.  
- `--norm_veto_th` — порог veto нормой (по умолчанию `0.90`).  
- `--sulfur_veto_th` — порог veto серной пробкой (по умолчанию `0.85`).  
- `--ng_margin` — минимальный зазор для приоритета негнойного отита (по умолчанию `0.10`).

При запуске скрипта с папкой изображений `data/Уши` и GT-таблицей `data/gt_converted_test.csv` на выходе должны получиться метрики:  

### 📊 Metrics (per class)

| Class       | Prec | Rec  | Spec | F1   | Acc  | Thr   |
|-------------|------|------|------|------|------|-------|
| NORM        | 0.900 | 0.970 | 0.876 | 0.934 | 0.927 | 0.500 |
| OP *(tuned)*| 0.868 | 0.805 | 0.985 | 0.835 | 0.966 | 0.019 |
| ONP *(tuned)*| 0.814 | 0.838 | 0.958 | 0.826 | 0.937 | 0.208 |
| CI          | 0.879 | 0.967 | 0.989 | 0.921 | 0.987 | 0.500 |
| OTH         | 0.509 | 0.643 | 0.923 | 0.568 | 0.892 | 0.500 |
  
